{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/yuanyinzhang256/house-price-predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from scipy.stats import skew\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.linear_model import ElasticNet, SGDRegressor, BayesianRidge\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./used_car_train_20200313.zip',sep=' ')\n",
    "test = pd.read_csv('./used_car_testA_20200313.zip',sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置pandas的打印参数\n",
    "pd.set_option('max_colwidth',50)\n",
    "pd.set_option('display.width',50)\n",
    "pd.set_option('display.max_columns',50)\n",
    "pd.set_option('display.max_rows',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SaleID</th>\n",
       "      <th>name</th>\n",
       "      <th>regDate</th>\n",
       "      <th>model</th>\n",
       "      <th>brand</th>\n",
       "      <th>bodyType</th>\n",
       "      <th>fuelType</th>\n",
       "      <th>gearbox</th>\n",
       "      <th>power</th>\n",
       "      <th>kilometer</th>\n",
       "      <th>notRepairedDamage</th>\n",
       "      <th>regionCode</th>\n",
       "      <th>seller</th>\n",
       "      <th>offerType</th>\n",
       "      <th>creatDate</th>\n",
       "      <th>price</th>\n",
       "      <th>v_0</th>\n",
       "      <th>v_1</th>\n",
       "      <th>v_2</th>\n",
       "      <th>v_3</th>\n",
       "      <th>v_4</th>\n",
       "      <th>v_5</th>\n",
       "      <th>v_6</th>\n",
       "      <th>v_7</th>\n",
       "      <th>v_8</th>\n",
       "      <th>v_9</th>\n",
       "      <th>v_10</th>\n",
       "      <th>v_11</th>\n",
       "      <th>v_12</th>\n",
       "      <th>v_13</th>\n",
       "      <th>v_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>20040402</td>\n",
       "      <td>30.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1046</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160404</td>\n",
       "      <td>1850</td>\n",
       "      <td>43.357796</td>\n",
       "      <td>3.966344</td>\n",
       "      <td>0.050257</td>\n",
       "      <td>2.159744</td>\n",
       "      <td>1.143786</td>\n",
       "      <td>0.235676</td>\n",
       "      <td>0.101988</td>\n",
       "      <td>0.129549</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.097462</td>\n",
       "      <td>-2.881803</td>\n",
       "      <td>2.804097</td>\n",
       "      <td>-2.420821</td>\n",
       "      <td>0.795292</td>\n",
       "      <td>0.914762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2262</td>\n",
       "      <td>20030301</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-</td>\n",
       "      <td>4366</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160309</td>\n",
       "      <td>3600</td>\n",
       "      <td>45.305273</td>\n",
       "      <td>5.236112</td>\n",
       "      <td>0.137925</td>\n",
       "      <td>1.380657</td>\n",
       "      <td>-1.422165</td>\n",
       "      <td>0.264777</td>\n",
       "      <td>0.121004</td>\n",
       "      <td>0.135731</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>-4.900482</td>\n",
       "      <td>2.096338</td>\n",
       "      <td>-1.030483</td>\n",
       "      <td>-1.722674</td>\n",
       "      <td>0.245522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14874</td>\n",
       "      <td>20040403</td>\n",
       "      <td>115.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160402</td>\n",
       "      <td>6222</td>\n",
       "      <td>45.978359</td>\n",
       "      <td>4.823792</td>\n",
       "      <td>1.319524</td>\n",
       "      <td>-0.998467</td>\n",
       "      <td>-0.996911</td>\n",
       "      <td>0.251410</td>\n",
       "      <td>0.114912</td>\n",
       "      <td>0.165147</td>\n",
       "      <td>0.062173</td>\n",
       "      <td>0.027075</td>\n",
       "      <td>-4.846749</td>\n",
       "      <td>1.803559</td>\n",
       "      <td>1.565330</td>\n",
       "      <td>-0.832687</td>\n",
       "      <td>-0.229963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>71865</td>\n",
       "      <td>19960908</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160312</td>\n",
       "      <td>2400</td>\n",
       "      <td>45.687478</td>\n",
       "      <td>4.492574</td>\n",
       "      <td>-0.050616</td>\n",
       "      <td>0.883600</td>\n",
       "      <td>-2.228079</td>\n",
       "      <td>0.274293</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.121964</td>\n",
       "      <td>0.033395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.509599</td>\n",
       "      <td>1.285940</td>\n",
       "      <td>-0.501868</td>\n",
       "      <td>-2.438353</td>\n",
       "      <td>-0.478699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>111080</td>\n",
       "      <td>20120103</td>\n",
       "      <td>110.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20160313</td>\n",
       "      <td>5200</td>\n",
       "      <td>44.383511</td>\n",
       "      <td>2.031433</td>\n",
       "      <td>0.572169</td>\n",
       "      <td>-1.571239</td>\n",
       "      <td>2.246088</td>\n",
       "      <td>0.228036</td>\n",
       "      <td>0.073205</td>\n",
       "      <td>0.091880</td>\n",
       "      <td>0.078819</td>\n",
       "      <td>0.121534</td>\n",
       "      <td>-1.896240</td>\n",
       "      <td>0.910783</td>\n",
       "      <td>0.931110</td>\n",
       "      <td>2.834518</td>\n",
       "      <td>1.923482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SaleID    name   regDate  model  brand  \\\n",
       "0       0     736  20040402   30.0      6   \n",
       "1       1    2262  20030301   40.0      1   \n",
       "2       2   14874  20040403  115.0     15   \n",
       "3       3   71865  19960908  109.0     10   \n",
       "4       4  111080  20120103  110.0      5   \n",
       "\n",
       "   bodyType  fuelType  gearbox  power  \\\n",
       "0       1.0       0.0      0.0     60   \n",
       "1       2.0       0.0      0.0      0   \n",
       "2       1.0       0.0      0.0    163   \n",
       "3       0.0       0.0      1.0    193   \n",
       "4       1.0       0.0      0.0     68   \n",
       "\n",
       "   kilometer notRepairedDamage  regionCode  \\\n",
       "0       12.5               0.0        1046   \n",
       "1       15.0                 -        4366   \n",
       "2       12.5               0.0        2806   \n",
       "3       15.0               0.0         434   \n",
       "4        5.0               0.0        6977   \n",
       "\n",
       "   seller  offerType  creatDate  price  \\\n",
       "0       0          0   20160404   1850   \n",
       "1       0          0   20160309   3600   \n",
       "2       0          0   20160402   6222   \n",
       "3       0          0   20160312   2400   \n",
       "4       0          0   20160313   5200   \n",
       "\n",
       "         v_0       v_1       v_2       v_3  \\\n",
       "0  43.357796  3.966344  0.050257  2.159744   \n",
       "1  45.305273  5.236112  0.137925  1.380657   \n",
       "2  45.978359  4.823792  1.319524 -0.998467   \n",
       "3  45.687478  4.492574 -0.050616  0.883600   \n",
       "4  44.383511  2.031433  0.572169 -1.571239   \n",
       "\n",
       "        v_4       v_5       v_6       v_7  \\\n",
       "0  1.143786  0.235676  0.101988  0.129549   \n",
       "1 -1.422165  0.264777  0.121004  0.135731   \n",
       "2 -0.996911  0.251410  0.114912  0.165147   \n",
       "3 -2.228079  0.274293  0.110300  0.121964   \n",
       "4  2.246088  0.228036  0.073205  0.091880   \n",
       "\n",
       "        v_8       v_9      v_10      v_11  \\\n",
       "0  0.022816  0.097462 -2.881803  2.804097   \n",
       "1  0.026597  0.020582 -4.900482  2.096338   \n",
       "2  0.062173  0.027075 -4.846749  1.803559   \n",
       "3  0.033395  0.000000 -4.509599  1.285940   \n",
       "4  0.078819  0.121534 -1.896240  0.910783   \n",
       "\n",
       "       v_12      v_13      v_14  \n",
       "0 -2.420821  0.795292  0.914762  \n",
       "1 -1.030483 -1.722674  0.245522  \n",
       "2  1.565330 -0.832687 -0.229963  \n",
       "3 -0.501868 -2.438353 -0.478699  \n",
       "4  0.931110  2.834518  1.923482  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-41e4b3d940ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.scatter(x=df.date_reg, y=df.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([train,test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['power']=df['power'].apply(lambda x:600 if x>600 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['notRepairedDamage']=df.notRepairedDamage.replace('-','2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price       50000\n",
       "fuelType    11573\n",
       "gearbox      7891\n",
       "bodyType     5919\n",
       "model           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = df.isnull().sum()\n",
    "aa[aa > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fuelType'].fillna(method='ffill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(method='bfill',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 因为年份是整型，而且从1000+开始，不合理\n",
    "class labelenc(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    # 对数据统一变换处理\n",
    "    def transform(self,X):\n",
    "        # 对数据编码，使编码后的数据更合理，且与元数据一一对应\n",
    "        # 编码后保持其大小关系\n",
    "        lab=LabelEncoder() \n",
    "        X[\"regDate\"] = lab.fit_transform(X[\"regDate\"])\n",
    "        X[\"creatDate\"] = lab.fit_transform(X[\"creatDate\"])\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class skew_dummies(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,skew=0.5):\n",
    "        self.skew = skew\n",
    "    \n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_numeric=X.select_dtypes(exclude=[\"object\"])\n",
    "        skewness = X_numeric.apply(lambda x: skew(x))\n",
    "        skewness_features = skewness[abs(skewness) >= self.skew].index\n",
    "        X[skewness_features] = np.log1p(X[skewness_features])\n",
    "        X = pd.get_dummies(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立流水线\n",
    "pipe = Pipeline([\n",
    "    ('labenc', labelenc()),\n",
    "    ('skew_dummies', skew_dummies(skew=1)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(['SaleID','price'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe = pipe.fit_transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pipe[['v_2','v_11','v_14']]=data_pipe[['v_2','v_11','v_14']].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use robustscaler since maybe there are other outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train=train.shape[0]\n",
    "\n",
    "X = data_pipe[:n_train]\n",
    "test_X = data_pipe[n_train:]\n",
    "y= train.price\n",
    "\n",
    "X_scaled = scaler.fit(X).transform(X)\n",
    "y_log = np.log(train.price)\n",
    "test_X_scaled = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征选择\n",
    "Combining different features is usually a good way, but we have no idea what features should we choose. Luckily there are some models that can provide feature selection, here I use Lasso, but you are free to choose Ridge, RandomForest or GradientBoostingTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso=Lasso(alpha=0.001)\n",
    "lasso.fit(X_scaled,y_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_lasso = pd.DataFrame({\"Feature Importance\":lasso.coef_}, index=data_pipe.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_lasso.sort_values(\"Feature Importance\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FI_lasso[FI_lasso[\"Feature Importance\"]!=0].sort_values(\"Feature Importance\").plot(kind=\"barh\",figsize=(15,25))\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled=pca.fit_transform(X_scaled)\n",
    "test_X_scaled = pca.transform(test_X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.shape, test_X_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cross validation strategy\n",
    "def rmse_cv(model,X,y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring=\"neg_mean_squared_error\", cv=5))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [LinearRegression(), Ridge(), Lasso(alpha=0.01,max_iter=10000), RandomForestRegressor(), GradientBoostingRegressor(),\n",
    "          SVR(), LinearSVR(), ElasticNet(alpha=0.001,max_iter=10000), SGDRegressor(max_iter=1000,tol=1e-3), BayesianRidge(),\n",
    "          KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5), ExtraTreesRegressor(), XGBRegressor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"LR\", \"Ridge\", \"Lasso\", \"RF\", \"GBR\", \"SVR\", \"LinSVR\", \"Ela\",\"SGD\",\"Bay\",\"Ker\",\"Extra\",\"XGB\"]\n",
    "for name, model in zip(names, models):\n",
    "    score = rmse_cv(model, X_scaled, y_log)\n",
    "    print(\"{:8s}:  {:.6f}, {:.4f}\".format(name, score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=0.0005,max_iter=10000)\n",
    "ridge = Ridge(alpha=60)\n",
    "svr = SVR(gamma= 0.0004,kernel='rbf',C=13,epsilon=0.009)\n",
    "ker = KernelRidge(alpha=0.2 ,kernel='polynomial',degree=3 , coef0=0.8)\n",
    "ela = ElasticNet(alpha=0.005,l1_ratio=0.08,max_iter=10000)\n",
    "bay = BayesianRidge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageWeight(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self,mod,weight):\n",
    "        self.mod = mod\n",
    "        self.weight = weight\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.models_ = [clone(x) for x in self.mod]\n",
    "        for model in self.models_:\n",
    "            model.fit(X,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        w = list()\n",
    "        pred = np.array([model.predict(X) for model in self.models_])\n",
    "        # for every data point, single model prediction times weight, then add them together\n",
    "        for data in range(pred.shape[1]):\n",
    "            single = [pred[model,data]*weight for model,weight in zip(range(pred.shape[0]),self.weight)]\n",
    "            w.append(np.sum(single))\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign weights based on their gridsearch score\n",
    "w1,w2,w3,w4,w5,w6 = (0.02, 0.2, 0.25, 0.3, 0.03, 0.2)\n",
    "weight_avg = AverageWeight(mod = [lasso,ridge,svr,ker,ela,bay],weight=[w1,w2,w3,w4,w5,w6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv(weight_avg, X_scaled, y_log),  rmse_cv(weight_avg, X_scaled, y_log).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_avg = AverageWeight(mod = [svr,ker],weight=[0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv(weight_avg,X_scaled,y_log), rmse_cv(weight_avg,X_scaled,y_log).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stacking(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, mod, meta_model):\n",
    "        self.mod = mod\n",
    "        self.meta_model = meta_model\n",
    "        self.kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        self.saved_model = [list() for i in self.mod]\n",
    "        oof_train = np.zeros((X.shape[0], len(self.mod)))\n",
    "        \n",
    "        for i,model in enumerate(self.mod):\n",
    "            for train_index, val_index in self.kf.split(X,y):\n",
    "                renew_model = clone(model)\n",
    "                renew_model.fit(X[train_index], y[train_index])\n",
    "                self.saved_model[i].append(renew_model)\n",
    "                oof_train[val_index,i] = renew_model.predict(X[val_index])\n",
    "        \n",
    "        self.meta_model.fit(oof_train,y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self,X):\n",
    "        whole_test = np.column_stack([np.column_stack(model.predict(X) for model in single_model).mean(axis=1) \n",
    "                                      for single_model in self.saved_model]) \n",
    "        return self.meta_model.predict(whole_test)\n",
    "    \n",
    "    def get_oof(self,X,y,test_X):\n",
    "        oof = np.zeros((X.shape[0],len(self.mod)))\n",
    "        test_single = np.zeros((test_X.shape[0],5))\n",
    "        test_mean = np.zeros((test_X.shape[0],len(self.mod)))\n",
    "        for i,model in enumerate(self.mod):\n",
    "            for j, (train_index,val_index) in enumerate(self.kf.split(X,y)):\n",
    "                clone_model = clone(model)\n",
    "                clone_model.fit(X[train_index],y[train_index])\n",
    "                oof[val_index,i] = clone_model.predict(X[val_index])\n",
    "                test_single[:,j] = clone_model.predict(test_X)\n",
    "            test_mean[:,i] = test_single.mean(axis=1)\n",
    "        return oof, test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# must do imputer first, otherwise stacking won't work, and i don't know why.\n",
    "a = Imputer().fit_transform(X_scaled)\n",
    "b = Imputer().fit_transform(y_log.values.reshape(-1,1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model = stacking(mod=[lasso,ridge,svr,ker,ela,bay],meta_model=ker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_cv(stack_model,a,b))\n",
    "print(rmse_cv(stack_model,a,b).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stack, X_test_stack = stack_model.get_oof(a,b,test_X_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stack.shape, a.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_add = np.hstack((a,X_train_stack))\n",
    "X_test_add = np.hstack((test_X_scaled,X_test_stack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_add.shape, X_test_add.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rmse_cv(stack_model,X_train_add,b))\n",
    "print(rmse_cv(stack_model,X_train_add,b).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model = stacking(mod=[lasso, ridge, svr, ker, ela, bay], meta_model=ker)\n",
    "stack_model.fit(a,b)\n",
    "pred = np.exp(stack_model.predict(test_X_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame({'Id':test.Id, 'SalePrice':pred})\n",
    "result.to_csv(\"submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
